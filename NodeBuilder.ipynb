{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8d149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"password\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf12cf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"RETURN 1 AS test\")\n",
    "    print(\"Connection successful\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da69790e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "with open('./pathCSV.txt','r') as f:\n",
    "    path = f.read()\n",
    "os.path.exists(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72cfa12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../filteredCSV/business.csv\n"
     ]
    }
   ],
   "source": [
    "business_path = \"business.csv\"\n",
    "review_path = \"review.csv\"\n",
    "# tip_path = \"yelp_academic_dataset_tip.json\"\n",
    "user_path = \"users.csv\"\n",
    "\n",
    "business_path, review_path, user_path = list(map(lambda y: path + '/' + y,[business_path, review_path, user_path]))\n",
    "# business_path, review_path, user_path = list(map(lambda y:'\"'+ path + '/' + y+'\"',[business_path, review_path, user_path]))\n",
    "print(business_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96810ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 being processed\n",
      "chunk converted to dicts\n",
      "chunk processed\n",
      "chunk 2 being processed\n",
      "chunk converted to dicts\n",
      "chunk processed\n",
      "chunk 3 being processed\n",
      "chunk converted to dicts\n",
      "chunk processed\n",
      "chunk 4 being processed\n",
      "chunk converted to dicts\n",
      "chunk processed\n"
     ]
    }
   ],
   "source": [
    "def import_csv(tx, csv_file_path, query):\n",
    "    with open(csv_file_path, 'r') as file:\n",
    "        tx.run(query, file=file)\n",
    "    # with open(csv_file_path, 'r') as file:\n",
    "    #     csv_data = file.read()\n",
    "    # tx.run(query,file=file)\n",
    "# csv_file_path = \"path/to/your/data.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Function to create nodes and relationships\n",
    "def create_graph(tx, data):\n",
    "    # for _, row in df.iterrows():\n",
    "        # query = \"\"\"CREATE (n:Businses  {name:$name,\n",
    "        #change this to use SET so that ubusiness ID is only thing that is unique that is tehre\n",
    "    query = \"\"\" UNWIND $business AS row\n",
    "            Create (n:Businsess  {business_id:row.business_id})\n",
    "            SET n.name=row.name, \n",
    "                n.address=row.address,\n",
    "                n.city=row.city,\n",
    "                n.state=row.state,\n",
    "                n.latitude=row.latitude,\n",
    "                n.longitude=row.longitude,\n",
    "                n.stars=row.stars,\n",
    "                n.review_count=row.review_count,\n",
    "                n.hours=row.hours,\n",
    "                n.attributes=row.attributes\n",
    "            With n, row\n",
    "            Merge (k:City {name: row.city, state: row.state})\n",
    "            Merge (s:State {name:row.state})\n",
    "            Merge (n)-[:IN_CITY]->(k)\n",
    "            Merge (k)-[:IN_STATE]->(s)\n",
    "            With n, split(row.categories,', ') as cats\n",
    "            unwind cats AS cat\n",
    "            merge (c:Category {name: cat})\n",
    "            Merge (n)-[:IN_CATEGORY]->(c)\n",
    "                \"\"\"\n",
    "\n",
    "    tx.run(query, business=data)\n",
    "\n",
    "chunk_size = 10000\n",
    "i=1\n",
    "for chunk in pd.read_csv(business_path, chunksize=chunk_size):\n",
    "    print(f\"chunk {i} being processed\")\n",
    "    users= chunk.to_dict('records')\n",
    "    print(\"chunk converted to dicts\")\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_graph, users)\n",
    "    print(\"chunk processed\")\n",
    "    i+=1\n",
    "\n",
    "# Close the driver\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aca7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 5 being processed\n",
      "chunk converted to dicts\n",
      "chunk processed\n",
      "chunk 6 being processed\n",
      "chunk converted to dicts\n",
      "chunk processed\n",
      "chunk 7 being processed\n",
      "chunk converted to dicts\n",
      "chunk processed\n",
      "chunk 8 being processed\n",
      "chunk converted to dicts\n",
      "chunk processed\n",
      "chunk 9 being processed\n",
      "chunk converted to dicts\n",
      "chunk processed\n",
      "chunk 10 being processed\n",
      "chunk converted to dicts\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to create nodes and relationships\n",
    "def create_graph(tx, users_data):\n",
    "    # for _, row in users.iterrows():\n",
    "    # use create instead of merge for faster \n",
    "    query = \"\"\"UNWIND $users AS row\n",
    "            Merge (n:User {user_id: row.user_id})\n",
    "                SET n.name = row.name,\n",
    "                    n.review_count = row.review_count,\n",
    "                    n.yelping_since = row.yelping_since,\n",
    "                    n.useful = row.useful,\n",
    "                    n.funny = row.funny,\n",
    "                    n.cool = row.cool,\n",
    "                    n.fans = row.fans,\n",
    "                    n.elite= row.elite,\n",
    "                    n.average_stars = row.average_stars,\n",
    "                    n.compliment_hot = row.compliment_hot,\n",
    "                    n.compliment_more = row.compliment_more,\n",
    "                    n.compliment_profile = row.compliment_profile,\n",
    "                    n.compliment_cute = row.compliment_cute,\n",
    "                    n.compliment_list = row.compliment_list,\n",
    "                    n.compliment_note = row.compliment_note,\n",
    "                    n.compliment_plain = row.compliment_plain,\n",
    "                    n.compliment_cool = row.compliment_cool,\n",
    "                    n.compliment_funny = row.compliment_funny,\n",
    "                    n.compliment_writer = row.compliment_writer\n",
    "            WITH n, row.friends AS frens\n",
    "            where frens = toString(frens)\n",
    "                UNWIND split(frens,\",\") AS friend_id\n",
    "                Merge (f:User {user_id: friend_id})\n",
    "                MERGE (n)-[:HAS_FRIEND]->(f)\n",
    "                \"\"\"\n",
    "    tx.run(query,users=users_data)\n",
    "\n",
    "# Execute the function within a transaction\n",
    "chunk_size = 5000\n",
    "i=1\n",
    "for chunk in pd.read_csv(user_path, chunksize=chunk_size):\n",
    "    if i>4: #already loaded 4 chunks\n",
    "        print(f\"chunk {i} being processed\")\n",
    "        users= chunk.to_dict('records')\n",
    "        print(\"chunk converted to dicts\")\n",
    "        with driver.session() as session:\n",
    "            session.execute_write(create_graph, users)\n",
    "        print(\"chunk processed\")\n",
    "    i+=1\n",
    "# Close the driver\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create nodes and relationships\n",
    "def create_graph(tx, users_data):\n",
    "    # for _, row in users.iterrows():\n",
    "    # use create instead of merge for faster \n",
    "    query = \"\"\"UNWIND $reviews AS row\n",
    "            CREATE (n:Review {review_id: row.review_id})\n",
    "                SET n.user_id = row.user_id,\n",
    "                    n.business_id = row.business_id,\n",
    "                    n.stars = row.stars,\n",
    "                    n.useful = row.useful,\n",
    "                    n.funny = row.funny,\n",
    "                    n.cool = row.cool,\n",
    "                    n.date = row.date,\n",
    "                    n.text = row.text\n",
    "            With n, n.user_id as user, n.business_id as business\n",
    "                Match (u:User {user_id:user})\n",
    "                Match (b:Business {business_id:business})\n",
    "                MERGE (u)-[rel:WRITES_REVIEW]->(n)\n",
    "                MERGE (n)-[rel:REVIEW_FOR]->(b)\n",
    "                \n",
    "                \"\"\"\n",
    "    tx.run(query,reviews=users_data)\n",
    "\n",
    "# Execute the function within a transaction\n",
    "chunk_size = 10000\n",
    "i=1\n",
    "for chunk in pd.read_csv(review_path, chunksize=chunk_size):\n",
    "    print(f\"chunk {i} being processed\")\n",
    "    reviews= chunk.to_dict('records')\n",
    "    print(\"chunk converted to dicts\")\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_graph, reviews)\n",
    "    print(\"chunk processed\")\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
